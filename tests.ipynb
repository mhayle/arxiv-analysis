{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is just a bunch of tests for functions in the other scripts. Nothing here matters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib, urllib.request\n",
    "from datetime import datetime\n",
    "import feedparser\n",
    "import urllib\n",
    "import time \n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<feed xmlns=\"http://www.w3.org/2005/Atom\">\n",
      "  <link href=\"http://arxiv.org/api/query?search_query%3Dall%26id_list%3D%26start%3D0%26max_results%3D1\" rel=\"self\" type=\"application/atom+xml\"/>\n",
      "  <title type=\"html\">ArXiv Query: search_query=all&amp;id_list=&amp;start=0&amp;max_results=1</title>\n",
      "  <id>http://arxiv.org/api/qNUQqYTSBqOn9wk3n+Jqa7/eio4</id>\n",
      "  <updated>2023-06-07T00:00:00-04:00</updated>\n",
      "  <opensearch:totalResults xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">327021</opensearch:totalResults>\n",
      "  <opensearch:startIndex xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">0</opensearch:startIndex>\n",
      "  <opensearch:itemsPerPage xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">1</opensearch:itemsPerPage>\n",
      "  <entry>\n",
      "    <id>http://arxiv.org/abs/1911.11405v1</id>\n",
      "    <updated>2019-11-26T08:49:54Z</updated>\n",
      "    <published>2019-11-26T08:49:54Z</published>\n",
      "    <title>A Note on Computational Complexity of Kill-all Go</title>\n",
      "    <summary>  Kill-all Go is a variant of Go in which Black tries to capture all white\n",
      "stones, while White tries to survive. We consider computational complexity of\n",
      "Kill-all Go with two rulesets, Chinese rules and Japanese rules. We prove that:\n",
      "(i) Kill-all Go with Chinese rules is PSPACE-hard, and (ii) Kill-all Go with\n",
      "Japanese rules is EXPTIME-complete.\n",
      "</summary>\n",
      "    <author>\n",
      "      <name>Zhujun Zhang</name>\n",
      "    </author>\n",
      "    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">15 pages, 11 figures</arxiv:comment>\n",
      "    <link href=\"http://arxiv.org/abs/1911.11405v1\" rel=\"alternate\" type=\"text/html\"/>\n",
      "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1911.11405v1\" rel=\"related\" type=\"application/pdf\"/>\n",
      "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CC\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.CC\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "  </entry>\n",
      "</feed>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = 'http://export.arxiv.org/api/query?search_query=all&start=0&max_results=1'\n",
    "data = urllib.request.urlopen(url)\n",
    "print(data.read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_url = 'http://export.arxiv.org/api/query?'\n",
    "\n",
    "# Search parameters\n",
    "search_query = 'all'  # search in all categories\n",
    "start = 0             # start at the first result\n",
    "total_results = 1000  # number of results to retrieve for each request\n",
    "\n",
    "current_result = start\n",
    "\n",
    "query = f'search_query={search_query}&start={start}&max_results={total_results}&sortBy=submittedDate&sortOrder=descending'\n",
    "response = urllib.request.urlopen(base_url+query).read()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "# Parsing the response\n",
    "feed = feedparser.parse(response)\n",
    "for entry in feed.entries:\n",
    "    data.append({\n",
    "        \"arXiv-id\": entry.id.split('/abs/')[-1].split('v')[0],\n",
    "        \"Title\": entry.title,\n",
    "        \"Summary\": entry.summary,\n",
    "        \"Published\": entry.published,\n",
    "        \"Updated\": entry.updated,\n",
    "        \"Authors\": \", \".join([author.name for author in entry.authors]),\n",
    "        \"Subject\": \" \".join([cat.term for cat in entry.tags])\n",
    "    })\n",
    "\n",
    "# Move on to the next results\n",
    "# current_result += total_results\n",
    "\n",
    "# Respectful crawling by sleeping\n",
    "# print(\"Sleeping for a while...\")\n",
    "# time.sleep(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-06-05 17:59:24'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date = '2023-06-05T17:59:24Z'\n",
    "form_date = datetime.strptime(date,\"%Y-%m-%dT%H:%M:%SZ\").strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "form_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-06-05'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "form_date.split(' ')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.now().date().strftime(\"%Y-%m-%d\")==form_date.split(' ')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arXiv-id': '2306.03907',\n",
       " 'Title': 'CL-UZH at SemEval-2023 Task 10: Sexism Detection through Incremental\\n  Fine-Tuning and Multi-Task Learning with Label Descriptions',\n",
       " 'Summary': 'The widespread popularity of social media has led to an increase in hateful,\\nabusive, and sexist language, motivating methods for the automatic detection of\\nsuch phenomena. The goal of the SemEval shared task \\\\textit{Towards Explainable\\nDetection of Online Sexism} (EDOS 2023) is to detect sexism in English social\\nmedia posts (subtask A), and to categorize such posts into four coarse-grained\\nsexism categories (subtask B), and eleven fine-grained subcategories (subtask\\nC). In this paper, we present our submitted systems for all three subtasks,\\nbased on a multi-task model that has been fine-tuned on a range of related\\ntasks and datasets before being fine-tuned on the specific EDOS subtasks. We\\nimplement multi-task learning by formulating each task as binary pairwise text\\nclassification, where the dataset and label descriptions are given along with\\nthe input text. The results show clear improvements over a fine-tuned\\nDeBERTa-V3 serving as a baseline leading to $F_1$-scores of 85.9\\\\% in subtask A\\n(rank 13/84), 64.8\\\\% in subtask B (rank 19/69), and 44.9\\\\% in subtask C\\n(26/63).',\n",
       " 'Published': '2023-06-06T17:59:49Z',\n",
       " 'Updated': '2023-06-06T17:59:49Z',\n",
       " 'Authors': 'Janis Goldzycher',\n",
       " 'Subject': 'cs.CL cs.CY'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'http://arxiv.org/abs/2306.03907v1',\n",
       " 'guidislink': True,\n",
       " 'link': 'http://arxiv.org/abs/2306.03907v1',\n",
       " 'updated': '2023-06-06T17:59:49Z',\n",
       " 'updated_parsed': time.struct_time(tm_year=2023, tm_mon=6, tm_mday=6, tm_hour=17, tm_min=59, tm_sec=49, tm_wday=1, tm_yday=157, tm_isdst=0),\n",
       " 'published': '2023-06-06T17:59:49Z',\n",
       " 'published_parsed': time.struct_time(tm_year=2023, tm_mon=6, tm_mday=6, tm_hour=17, tm_min=59, tm_sec=49, tm_wday=1, tm_yday=157, tm_isdst=0),\n",
       " 'title': 'CL-UZH at SemEval-2023 Task 10: Sexism Detection through Incremental\\n  Fine-Tuning and Multi-Task Learning with Label Descriptions',\n",
       " 'title_detail': {'type': 'text/plain',\n",
       "  'language': None,\n",
       "  'base': '',\n",
       "  'value': 'CL-UZH at SemEval-2023 Task 10: Sexism Detection through Incremental\\n  Fine-Tuning and Multi-Task Learning with Label Descriptions'},\n",
       " 'summary': 'The widespread popularity of social media has led to an increase in hateful,\\nabusive, and sexist language, motivating methods for the automatic detection of\\nsuch phenomena. The goal of the SemEval shared task \\\\textit{Towards Explainable\\nDetection of Online Sexism} (EDOS 2023) is to detect sexism in English social\\nmedia posts (subtask A), and to categorize such posts into four coarse-grained\\nsexism categories (subtask B), and eleven fine-grained subcategories (subtask\\nC). In this paper, we present our submitted systems for all three subtasks,\\nbased on a multi-task model that has been fine-tuned on a range of related\\ntasks and datasets before being fine-tuned on the specific EDOS subtasks. We\\nimplement multi-task learning by formulating each task as binary pairwise text\\nclassification, where the dataset and label descriptions are given along with\\nthe input text. The results show clear improvements over a fine-tuned\\nDeBERTa-V3 serving as a baseline leading to $F_1$-scores of 85.9\\\\% in subtask A\\n(rank 13/84), 64.8\\\\% in subtask B (rank 19/69), and 44.9\\\\% in subtask C\\n(26/63).',\n",
       " 'summary_detail': {'type': 'text/plain',\n",
       "  'language': None,\n",
       "  'base': '',\n",
       "  'value': 'The widespread popularity of social media has led to an increase in hateful,\\nabusive, and sexist language, motivating methods for the automatic detection of\\nsuch phenomena. The goal of the SemEval shared task \\\\textit{Towards Explainable\\nDetection of Online Sexism} (EDOS 2023) is to detect sexism in English social\\nmedia posts (subtask A), and to categorize such posts into four coarse-grained\\nsexism categories (subtask B), and eleven fine-grained subcategories (subtask\\nC). In this paper, we present our submitted systems for all three subtasks,\\nbased on a multi-task model that has been fine-tuned on a range of related\\ntasks and datasets before being fine-tuned on the specific EDOS subtasks. We\\nimplement multi-task learning by formulating each task as binary pairwise text\\nclassification, where the dataset and label descriptions are given along with\\nthe input text. The results show clear improvements over a fine-tuned\\nDeBERTa-V3 serving as a baseline leading to $F_1$-scores of 85.9\\\\% in subtask A\\n(rank 13/84), 64.8\\\\% in subtask B (rank 19/69), and 44.9\\\\% in subtask C\\n(26/63).'},\n",
       " 'authors': [{'name': 'Janis Goldzycher'}],\n",
       " 'author_detail': {'name': 'Janis Goldzycher'},\n",
       " 'author': 'Janis Goldzycher',\n",
       " 'arxiv_comment': '11 pages, 4 figures, Accepted at The 17th International Workshop on\\n  Semantic Evaluation, ACL 2023',\n",
       " 'links': [{'href': 'http://arxiv.org/abs/2306.03907v1',\n",
       "   'rel': 'alternate',\n",
       "   'type': 'text/html'},\n",
       "  {'title': 'pdf',\n",
       "   'href': 'http://arxiv.org/pdf/2306.03907v1',\n",
       "   'rel': 'related',\n",
       "   'type': 'application/pdf'}],\n",
       " 'arxiv_primary_category': {'term': 'cs.CL',\n",
       "  'scheme': 'http://arxiv.org/schemas/atom'},\n",
       " 'tags': [{'term': 'cs.CL',\n",
       "   'scheme': 'http://arxiv.org/schemas/atom',\n",
       "   'label': None},\n",
       "  {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed.entries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arXiv-id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Published</th>\n",
       "      <th>Updated</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2306.03907</td>\n",
       "      <td>CL-UZH at SemEval-2023 Task 10: Sexism Detecti...</td>\n",
       "      <td>The widespread popularity of social media has ...</td>\n",
       "      <td>2023-06-06T17:59:49Z</td>\n",
       "      <td>2023-06-06T17:59:49Z</td>\n",
       "      <td>Janis Goldzycher</td>\n",
       "      <td>cs.CL cs.CY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2306.03900</td>\n",
       "      <td>Model Spider: Learning to Rank Pre-Trained Mod...</td>\n",
       "      <td>Figuring out which Pre-Trained Model (PTM) fro...</td>\n",
       "      <td>2023-06-06T17:58:12Z</td>\n",
       "      <td>2023-06-06T17:58:12Z</td>\n",
       "      <td>Yi-Kai Zhang, Ting-Ji Huang, Yao-Xiang Ding, D...</td>\n",
       "      <td>cs.LG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2306.03898</td>\n",
       "      <td>Thermalization of Non-Fermi Liquid Electron-Ph...</td>\n",
       "      <td>We study thermalization dynamics in a fermion-...</td>\n",
       "      <td>2023-06-06T17:57:18Z</td>\n",
       "      <td>2023-06-06T17:57:18Z</td>\n",
       "      <td>Hossein Hosseinabadi, Shane P. Kelly, Jörg Sch...</td>\n",
       "      <td>cond-mat.str-el hep-th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2306.03895</td>\n",
       "      <td>Synchronous micromechanically resonant program...</td>\n",
       "      <td>Programmable photonic integrated circuits (PIC...</td>\n",
       "      <td>2023-06-06T17:55:47Z</td>\n",
       "      <td>2023-06-06T17:55:47Z</td>\n",
       "      <td>Mark Dong, Julia M. Boyle, Kevin J. Palm, Matt...</td>\n",
       "      <td>physics.optics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306.03894</td>\n",
       "      <td>Fractals from Regular Behaviours</td>\n",
       "      <td>We are interested in connections between the t...</td>\n",
       "      <td>2023-06-06T17:55:12Z</td>\n",
       "      <td>2023-06-06T17:55:12Z</td>\n",
       "      <td>Todd Schmid, Victoria Noquez, Lawrence S. Moss</td>\n",
       "      <td>cs.LO cs.FL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     arXiv-id                                              Title  \\\n",
       "0  2306.03907  CL-UZH at SemEval-2023 Task 10: Sexism Detecti...   \n",
       "1  2306.03900  Model Spider: Learning to Rank Pre-Trained Mod...   \n",
       "2  2306.03898  Thermalization of Non-Fermi Liquid Electron-Ph...   \n",
       "3  2306.03895  Synchronous micromechanically resonant program...   \n",
       "4  2306.03894                   Fractals from Regular Behaviours   \n",
       "\n",
       "                                             Summary             Published  \\\n",
       "0  The widespread popularity of social media has ...  2023-06-06T17:59:49Z   \n",
       "1  Figuring out which Pre-Trained Model (PTM) fro...  2023-06-06T17:58:12Z   \n",
       "2  We study thermalization dynamics in a fermion-...  2023-06-06T17:57:18Z   \n",
       "3  Programmable photonic integrated circuits (PIC...  2023-06-06T17:55:47Z   \n",
       "4  We are interested in connections between the t...  2023-06-06T17:55:12Z   \n",
       "\n",
       "                Updated                                            Authors  \\\n",
       "0  2023-06-06T17:59:49Z                                   Janis Goldzycher   \n",
       "1  2023-06-06T17:58:12Z  Yi-Kai Zhang, Ting-Ji Huang, Yao-Xiang Ding, D...   \n",
       "2  2023-06-06T17:57:18Z  Hossein Hosseinabadi, Shane P. Kelly, Jörg Sch...   \n",
       "3  2023-06-06T17:55:47Z  Mark Dong, Julia M. Boyle, Kevin J. Palm, Matt...   \n",
       "4  2023-06-06T17:55:12Z     Todd Schmid, Victoria Noquez, Lawrence S. Moss   \n",
       "\n",
       "                  Subject  \n",
       "0             cs.CL cs.CY  \n",
       "1                   cs.LG  \n",
       "2  cond-mat.str-el hep-th  \n",
       "3          physics.optics  \n",
       "4             cs.LO cs.FL  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data).head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Zhujun Zhang'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed.entries[0].authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'term': 'cs.CC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed.entries[0].tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x157000368f0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('arxiv_metadata.db')\n",
    "c = conn.cursor()\n",
    "\n",
    "# Create table\n",
    "c.execute('''CREATE TABLE IF NOT EXISTS metadata\n",
    "             (arxiv_id TEXT, title TEXT, summary TEXT, published TEXT, updated TEXT, authors TEXT)''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import requests\n",
    "base_url = 'http://export.arxiv.org/oai2'\n",
    "params = {'verb': 'ListRecords', 'metadataPrefix': 'arXivRaw'}\n",
    "# response = requests.get(base_url, params=params)\n",
    "#response = requests.get(\"https://export.arxiv.org/oai2?verb=ListRecords&resumptionToken={resumptionToken}\")\n",
    "response = requests.get(\"http://export.arxiv.org/oai2?verb=ListRecords&metadataPrefix=arXivRaw&from=2023-06-01\")\n",
    "root = ET.fromstring(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-06-05'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date\n",
    "date.today().strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "namespace = {'OAI': 'http://www.openarchives.org/OAI/2.0/','arXiv': 'http://arxiv.org/OAI/arXivRaw/'}\n",
    "resumptionToken = root.find('.//OAI:resumptionToken', namespace)\n",
    "# root.findall(\".//OAI:record\", namespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = root.findall(\n",
    "        'OAI:ListRecords/OAI:record/OAI:metadata/arXiv:arXivRaw',\n",
    "        namespace\n",
    "    )\n",
    "# temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[1].find('arXiv:{}'.format('version'), namespace).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mrmus\\Documents\\GitHub\\arxiv-analysis\\arxiv_analysis.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mrmus/Documents/GitHub/arxiv-analysis/arxiv_analysis.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m [i\u001b[39m.\u001b[39mattrib \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m  temp[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39mfindall(\u001b[39m'\u001b[39m\u001b[39marXiv:\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39m'\u001b[39m\u001b[39mversion\u001b[39m\u001b[39m'\u001b[39m), namespace)]\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "[i.attrib for i in  temp[0].findall('arXiv:{}'.format('version'), namespace)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_parser(elm):\n",
    "    \n",
    "    dates = [\n",
    "        subnode.text\n",
    "        for node in elm.findall(\"arXiv:{}\".format(\"version\"), namespace)\n",
    "        for subnode in node.findall(\"arXiv:{}\".format(\"date\"), namespace)\n",
    "    ]\n",
    "\n",
    "    new_dates = [datetime.strptime(d, \"%a, %d %b %Y %H:%M:%S %Z\").strftime('%Y-%m-%d %H:%M:%S') for d in dates]\n",
    "    \n",
    "    published = new_dates[0]\n",
    "    updated = new_dates[len(new_dates)-1]\n",
    "\n",
    "    return published, updated\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def parse_record(r):\n",
    "\n",
    "    # resumptionToken = root.find(\n",
    "    #     'OAI:ListRecords/OAI:resumptionToken',\n",
    "    #     namespace\n",
    "    # )\n",
    "    # resumptionToken = resumptionToken.text if resumptionToken is not None else ''\n",
    "\n",
    "    # records = root.findall(\n",
    "    #     'OAI:ListRecords/OAI:record/OAI:metadata/arXiv:arXivRaw',\n",
    "    #     namespace\n",
    "    # )\n",
    "\n",
    "    #for r in records:\n",
    "\n",
    "    arxiv_id = r.find('arXiv:{}'.format('id'), namespace).text\n",
    "    title = r.find('arXiv:{}'.format('title'), namespace).text\n",
    "    abstract = r.find('arXiv:{}'.format('abstract'), namespace).text\n",
    "    published, updated = date_parser(r)\n",
    "    authors = r.find('arXiv:{}'.format('authors'), namespace).text\n",
    "    subjects = r.find('arXiv:{}'.format('categories'), namespace).text\n",
    "\n",
    "    records = (arxiv_id, title, abstract, published, updated, authors, subjects)\n",
    "        \n",
    "    return records#, resumptionToken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'2023-06-05' > '2023-06-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in temp:\n",
    "    print(parse_record(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mrmus\\Documents\\GitHub\\arxiv-analysis\\arxiv_analysis.ipynb Cell 27\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mrmus/Documents/GitHub/arxiv-analysis/arxiv_analysis.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m record, res \u001b[39m=\u001b[39m parse_record(root)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mrmus/Documents/GitHub/arxiv-analysis/arxiv_analysis.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m record\n",
      "\u001b[1;32mc:\\Users\\mrmus\\Documents\\GitHub\\arxiv-analysis\\arxiv_analysis.ipynb Cell 27\u001b[0m in \u001b[0;36mparse_record\u001b[1;34m(r)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mrmus/Documents/GitHub/arxiv-analysis/arxiv_analysis.ipynb#X26sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse_record\u001b[39m(r):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mrmus/Documents/GitHub/arxiv-analysis/arxiv_analysis.ipynb#X26sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mrmus/Documents/GitHub/arxiv-analysis/arxiv_analysis.ipynb#X26sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39m# resumptionToken = root.find(\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mrmus/Documents/GitHub/arxiv-analysis/arxiv_analysis.ipynb#X26sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mrmus/Documents/GitHub/arxiv-analysis/arxiv_analysis.ipynb#X26sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     \u001b[39m#for r in records:\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mrmus/Documents/GitHub/arxiv-analysis/arxiv_analysis.ipynb#X26sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     arxiv_id \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39;49mfind(\u001b[39m'\u001b[39;49m\u001b[39marXiv:\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mformat(\u001b[39m'\u001b[39;49m\u001b[39mid\u001b[39;49m\u001b[39m'\u001b[39;49m), namespace)\u001b[39m.\u001b[39;49mtext\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mrmus/Documents/GitHub/arxiv-analysis/arxiv_analysis.ipynb#X26sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     title \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39marXiv:\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m), namespace)\u001b[39m.\u001b[39mtext\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mrmus/Documents/GitHub/arxiv-analysis/arxiv_analysis.ipynb#X26sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     abstract \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39marXiv:\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39m'\u001b[39m\u001b[39mabstract\u001b[39m\u001b[39m'\u001b[39m), namespace)\u001b[39m.\u001b[39mtext\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "record, res = parse_record(root)\n",
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2013-01-20 22:28:30', '2023-06-02 04:21:21')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_dates = [\n",
    "    subnode.text\n",
    "    for node in temp[2].findall(\"arXiv:{}\".format(\"version\"), namespace)\n",
    "    for subnode in node.findall(\"arXiv:{}\".format(\"date\"), namespace)\n",
    "]\n",
    "\n",
    "date_parser(temp[0])\n",
    "\n",
    "# print(temp_dates[0])\n",
    "\n",
    "# dt_object = datetime.strptime(temp_dates[0], \"%a, %d %b %Y %H:%M:%S %Z\").strftime('%Y-%m-%d %H:%M:%S')\n",
    "# # print(dt_object.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "# print(dt_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('asdf', 'asdf', 'asdf')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp2 = ('asdf','asdf','asdf')\n",
    "temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element '{http://www.openarchives.org/OAI/2.0/}resumptionToken' at 0x000002A56C643220>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumptionToken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'http://arxiv.org/abs/2306.03907v1',\n",
       " 'guidislink': True,\n",
       " 'link': 'http://arxiv.org/abs/2306.03907v1',\n",
       " 'updated': '2023-06-06T17:59:49Z',\n",
       " 'updated_parsed': time.struct_time(tm_year=2023, tm_mon=6, tm_mday=6, tm_hour=17, tm_min=59, tm_sec=49, tm_wday=1, tm_yday=157, tm_isdst=0),\n",
       " 'published': '2023-06-06T17:59:49Z',\n",
       " 'published_parsed': time.struct_time(tm_year=2023, tm_mon=6, tm_mday=6, tm_hour=17, tm_min=59, tm_sec=49, tm_wday=1, tm_yday=157, tm_isdst=0),\n",
       " 'title': 'CL-UZH at SemEval-2023 Task 10: Sexism Detection through Incremental\\n  Fine-Tuning and Multi-Task Learning with Label Descriptions',\n",
       " 'title_detail': {'type': 'text/plain',\n",
       "  'language': None,\n",
       "  'base': '',\n",
       "  'value': 'CL-UZH at SemEval-2023 Task 10: Sexism Detection through Incremental\\n  Fine-Tuning and Multi-Task Learning with Label Descriptions'},\n",
       " 'summary': 'The widespread popularity of social media has led to an increase in hateful,\\nabusive, and sexist language, motivating methods for the automatic detection of\\nsuch phenomena. The goal of the SemEval shared task \\\\textit{Towards Explainable\\nDetection of Online Sexism} (EDOS 2023) is to detect sexism in English social\\nmedia posts (subtask A), and to categorize such posts into four coarse-grained\\nsexism categories (subtask B), and eleven fine-grained subcategories (subtask\\nC). In this paper, we present our submitted systems for all three subtasks,\\nbased on a multi-task model that has been fine-tuned on a range of related\\ntasks and datasets before being fine-tuned on the specific EDOS subtasks. We\\nimplement multi-task learning by formulating each task as binary pairwise text\\nclassification, where the dataset and label descriptions are given along with\\nthe input text. The results show clear improvements over a fine-tuned\\nDeBERTa-V3 serving as a baseline leading to $F_1$-scores of 85.9\\\\% in subtask A\\n(rank 13/84), 64.8\\\\% in subtask B (rank 19/69), and 44.9\\\\% in subtask C\\n(26/63).',\n",
       " 'summary_detail': {'type': 'text/plain',\n",
       "  'language': None,\n",
       "  'base': '',\n",
       "  'value': 'The widespread popularity of social media has led to an increase in hateful,\\nabusive, and sexist language, motivating methods for the automatic detection of\\nsuch phenomena. The goal of the SemEval shared task \\\\textit{Towards Explainable\\nDetection of Online Sexism} (EDOS 2023) is to detect sexism in English social\\nmedia posts (subtask A), and to categorize such posts into four coarse-grained\\nsexism categories (subtask B), and eleven fine-grained subcategories (subtask\\nC). In this paper, we present our submitted systems for all three subtasks,\\nbased on a multi-task model that has been fine-tuned on a range of related\\ntasks and datasets before being fine-tuned on the specific EDOS subtasks. We\\nimplement multi-task learning by formulating each task as binary pairwise text\\nclassification, where the dataset and label descriptions are given along with\\nthe input text. The results show clear improvements over a fine-tuned\\nDeBERTa-V3 serving as a baseline leading to $F_1$-scores of 85.9\\\\% in subtask A\\n(rank 13/84), 64.8\\\\% in subtask B (rank 19/69), and 44.9\\\\% in subtask C\\n(26/63).'},\n",
       " 'authors': [{'name': 'Janis Goldzycher'}],\n",
       " 'author_detail': {'name': 'Janis Goldzycher'},\n",
       " 'author': 'Janis Goldzycher',\n",
       " 'arxiv_comment': '11 pages, 4 figures, Accepted at The 17th International Workshop on\\n  Semantic Evaluation, ACL 2023',\n",
       " 'links': [{'href': 'http://arxiv.org/abs/2306.03907v1',\n",
       "   'rel': 'alternate',\n",
       "   'type': 'text/html'},\n",
       "  {'title': 'pdf',\n",
       "   'href': 'http://arxiv.org/pdf/2306.03907v1',\n",
       "   'rel': 'related',\n",
       "   'type': 'application/pdf'}],\n",
       " 'arxiv_primary_category': {'term': 'cs.CL',\n",
       "  'scheme': 'http://arxiv.org/schemas/atom'},\n",
       " 'tags': [{'term': 'cs.CL',\n",
       "   'scheme': 'http://arxiv.org/schemas/atom',\n",
       "   'label': None},\n",
       "  {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url = 'http://export.arxiv.org/api/query?'\n",
    "search_query = 'all'  # search in all categories\n",
    "start = 0             # start at the first result\n",
    "total_results = 1000  # number of results to retrieve for each request\n",
    "\n",
    "def fetch_data(start):\n",
    "    query = f'search_query={search_query}&start={start}&max_results={total_results}&sortBy=submittedDate&sortOrder=descending'\n",
    "    response = requests.get(base_url + query)\n",
    "    feed = feedparser.parse(response.content)\n",
    "    return feed\n",
    "\n",
    "current_result = start\n",
    "temp_results = fetch_data(current_result)\n",
    "temp_results.entries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
